{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's be rebels and ignore warnings for now\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Visualization \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotly imports\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other imports\n",
    "from collections import Counter\n",
    "from scipy.misc import imread\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING ALL THE NECESSARY LIBRARIES AND PACKAGES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>@manjulamartin @Kirk_Gleason Except trains are...</td>\n",
       "      <td>manjulamartin kirk gleason except train capita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I want a Google driverless car.</td>\n",
       "      <td>want google driverless car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>@Oatmeal @google driverless @TeslaMotors ? Ooo...</td>\n",
       "      <td>oatmeal google driverless teslamotors ooooh wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>SO MUCH AWESOME! Amazing video for GoogleÌ¢‰âÂ...</td>\n",
       "      <td>much awesome amazing video google next phase d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@google is making driverless cars which is awe...</td>\n",
       "      <td>google making driverless car awesome http co h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          5  @manjulamartin @Kirk_Gleason Except trains are...   \n",
       "1          5                    I want a Google driverless car.   \n",
       "2          5  @Oatmeal @google driverless @TeslaMotors ? Ooo...   \n",
       "3          5  SO MUCH AWESOME! Amazing video for GoogleÌ¢‰âÂ...   \n",
       "4          5  @google is making driverless cars which is awe...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  manjulamartin kirk gleason except train capita...  \n",
       "1                         want google driverless car  \n",
       "2  oatmeal google driverless teslamotors ooooh wo...  \n",
       "3  much awesome amazing video google next phase d...  \n",
       "4  google making driverless car awesome http co h...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOADING THE DATASET AND SEEING THE DETAILS\n",
    "data = pd.read_csv('train_self_drive_clean.csv', index_col= None)\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentiment', 'text', 'cleaned'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset:\n",
      "(981, 3)\n"
     ]
    }
   ],
   "source": [
    "# SHAPE OF THE DATASET\n",
    "print(\"Shape of the dataset:\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Two places I'd invest all my money if I could:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Awesome! Google driverless cars will help the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Autonomous vehicles could reduce traffic fatal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Really good presentation from Jan Becker on Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ford just revealed it's Automated Ford Fusion ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   1  Two places I'd invest all my money if I could:...\n",
       "1   2  Awesome! Google driverless cars will help the ...\n",
       "2   3  Autonomous vehicles could reduce traffic fatal...\n",
       "3   4  Really good presentation from Jan Becker on Bo...\n",
       "4   5  Ford just revealed it's Automated Ford Fusion ..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of each column:\n",
      "sentiment     int64\n",
      "text         object\n",
      "cleaned      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# DATATYPE OF EACH COLUMN\n",
    "print(\"Datatype of each column:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>981.000000</td>\n",
       "      <td>981</td>\n",
       "      <td>981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>981</td>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Q: Why are driverless cars all Prius? A: Drivi...</td>\n",
       "      <td>driverless car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.136595</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.786166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                               text  \\\n",
       "count   981.000000                                                981   \n",
       "unique         NaN                                                981   \n",
       "top            NaN  Q: Why are driverless cars all Prius? A: Drivi...   \n",
       "freq           NaN                                                  1   \n",
       "mean      3.136595                                                NaN   \n",
       "std       0.786166                                                NaN   \n",
       "min       1.000000                                                NaN   \n",
       "25%       3.000000                                                NaN   \n",
       "50%       3.000000                                                NaN   \n",
       "75%       3.000000                                                NaN   \n",
       "max       5.000000                                                NaN   \n",
       "\n",
       "               cleaned  \n",
       "count              981  \n",
       "unique             978  \n",
       "top     driverless car  \n",
       "freq                 2  \n",
       "mean               NaN  \n",
       "std                NaN  \n",
       "min                NaN  \n",
       "25%                NaN  \n",
       "50%                NaN  \n",
       "75%                NaN  \n",
       "max                NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATASET SUMMARY\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    603\n",
       "4    179\n",
       "2    117\n",
       "5     59\n",
       "1     23\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dependant variable for future modeling\n",
    "y=data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>@manjulamartin @Kirk_Gleason Except trains are...</td>\n",
       "      <td>manjulamartin kirk gleason except train capita...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I want a Google driverless car.</td>\n",
       "      <td>want google driverless car</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>@Oatmeal @google driverless @TeslaMotors ? Ooo...</td>\n",
       "      <td>oatmeal google driverless teslamotors ooooh wo...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>SO MUCH AWESOME! Amazing video for GoogleÌ¢‰âÂ...</td>\n",
       "      <td>much awesome amazing video google next phase d...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@google is making driverless cars which is awe...</td>\n",
       "      <td>google making driverless car awesome http co h...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          5  @manjulamartin @Kirk_Gleason Except trains are...   \n",
       "1          5                    I want a Google driverless car.   \n",
       "2          5  @Oatmeal @google driverless @TeslaMotors ? Ooo...   \n",
       "3          5  SO MUCH AWESOME! Amazing video for GoogleÌ¢‰âÂ...   \n",
       "4          5  @google is making driverless cars which is awe...   \n",
       "\n",
       "                                             cleaned  length  \n",
       "0  manjulamartin kirk gleason except train capita...     140  \n",
       "1                         want google driverless car      31  \n",
       "2  oatmeal google driverless teslamotors ooooh wo...      72  \n",
       "3  much awesome amazing video google next phase d...     116  \n",
       "4  google making driverless car awesome http co h...      73  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CREATING A NEW COLUMN IN THE DATASET FOR THE NUMBER OF WORDS IN THE REVIEW\n",
    "data['length'] = data['text'].apply(len)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1ecfc7ce198>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAADQCAYAAADxn5GHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGpJJREFUeJzt3X/QbHddH/D3p7lBkaQNyE0mJkyDNRVRhxBvUygtI1AhRGviDwTHscHGyXSqFtvaGuvUYmtHsf6eOtog6LXyIwzCJOoUSNNktBUjFwgkMWIwphJIc28qaNJWKPHTP/bc5MnNc++zz7Pnefbss6/XzJndPXvO2c/u2ffz47Pfc7a6OwAAAABT9peWXQAAAADAVjQwAAAAgMnTwAAAAAAmTwMDAAAAmDwNDAAAAGDyNDAAAACAydPAWAFVdVFVXbbh9tdW1TW7/JhfWVV/a6Rt/buq+lhVPTzG9mCnVjlLVfV5VfUbVfX7VXVnVf3IGPXBTqxyloZtvauqPjRk6eer6rQxtgvbseo52rDNG6rqjjG3Cdux6lmqqluq6iNVddswnT3GdvcrDYzVcFGSR0PZ3Td0927/8/KVScb6BfdrSS4ZaVuwiFXP0o9197OSPDfJC6rq5SNtF7Zr1bP0Td39nCRfluRgkleMtF3YjlXPUarq65P4gIplW/ksJfmW7r5omI6OuN19p7p72TXsW1X1lCRvS3J+ktOS/Nvuvq6qviLJTyQ5I8mDSV7d3fdX1S1Jbk3yoiRnJblquP3RJE9O8vEkPzxcP9Td31lVv5Tk/yZ5VpK/muTbklyZ5PlJbu3uVw+1vDTJDyb5nCR/mOTbuvvhqro3yeEkfy/J6Zn9EffnSX4nySNJjiX5ru7+rRFej4e7+4xFt8P6kaVNX5OfTnJHd79+jO2xHmTpCa/H6UnekeRXuvu6RbfHepCjR1+HM5K8K8nVSd7W3V+2022xnmTp0dfhliTf091HdrqNtdLdpl2aknxDktdvuP1XMnvj/3aSg8O8VyZ543D9liQ/Ply/LMl/Ga6/Osl/2LCdR28n+aUkb01SSS5P8mdJvjyz0TXvz6wj+fQkv5nkKcM635vkB4br92YWuiT5R0l+Ybj+2syCtNnzelGS2zaZfnuL1+PhZe8T02pOsvSE9c5Kck+SL1z2vjGt1iRLj1vn3Uk+meTNSU5b9r4xrc4kR48u/5NJvi7JBZk11Je+b0yrNcnSo8vfkuT2YZl/lWGQgWnz6UDYTbcn+bGqel2SX+/u36qqL8tsyOqNVZXMuo33b1jnHcPl+zP7hTCPX+vurqrbkzzQ3bcnSVXdOWzj/CTPTvLfh8d8UpL3nuQxv36rB+vumzMLO+wVWRpU1YEkb0nyM919z3bWhcjSxnVeVlWfm+RNSV6c5MbtrM9aW/scVdVFSb6ou/9JVV0wzzqwibXP0uBbuvvjVXVmkl9N8q1Jfnkb668VDYxd1N1/MAyBuizJD1fVe5K8M8md3f38k6z26eHykcy/f46v8xcbrh+/fWDY1o3d/c1jPGZVvSizrvuJ/k93j3piKEhk6QTXJrm7u39qq+3DiWTp8br7z6vqhsw+ldPAYC5ylGQ2/P4rhuH1B5KcXVW3dPdXbvU4cJwszXT3x4fLh6rqzZmdO1AD4yScxHMXVdUXZPZG/ZUkP5bk4iQfSXKwqp4/LHN6VX3pFpt6KMmZC5TyO5md8O+Lhsf8vKr66zt9zO6+uR87yczGSfOCXSFLM1X1Q5kNr/zuBZ4Da0yWZsftV9W5w/UDmf3h/PsLPBfWjBwl3f1z3f0F3X1Bkr+d5A80L9guWZr9Hqqqpw/XT0/yNUl8q88paGDsri9P8rtVdVuS70/yQ939mSTfmOR1VfWhzI512uof/5uTPLtmX6vzyu0W0d3HMjsW7C1V9eHMQvqsLVb7tSRfNzzm39nuY25UVT9aVfcl+byquq+qXrvI9lhLa5+lqjo/s+f+7CQfGLb37TvdHmtr7bOU5ClJbhge90NJjib5+QW2x/qRIxiHLM1OGvru4XFvy+xEpE7Qfgq+hQQAAACYPCMwAAAAgMnTwAAAAAAmTwMDAAAAmDwNDAAAAGDy9rSBcemll3YSk2mdp4XJkck0DlkymcYhS6Y1n0YhRybTfPa0gfHggw/u5cPBviRHMA5ZgnHIEixOjmA+DiEBAAAAJk8DAwAAAJg8DQwAAABg8jQwAAAAgMnTwAAAAAAmTwMDAAAAmLwDyy4AAGAvVD12vef+xnkAYCqMwAAAAAAmTwMDAAAAmDwNDAAAAGDyNDAAAACAydPAAAAAACZPAwMAAACYPA0MAAAAYPI0MAAAAIDJm6uBUVVnVdXbq+r3q+quqnp+VT2tqm6sqruHy6fudrEAAADAepp3BMZPJ3lXdz8ryXOS3JXkmiQ3dfeFSW4abgMAAACMbssGRlX95SQvTPKGJOnuz3T3p5JcnuTwsNjhJFfsVpEAAADAeptnBMYXJjmW5Ber6oNV9QtV9ZQk53T3/UkyXJ692cpVdXVVHamqI8eOHRutcFgncgTjkCUYhyzB4uQItm+eBsaBJBcn+bnufm6S/51tHC7S3dd296HuPnTw4MEdlgnrTY5gHLIE45AlWJwcwfbN08C4L8l93X3rcPvtmTU0Hqiqc5NkuDy6OyUCAAAA627LBkZ3/88kH6uqLx5mvSTJ7yW5IcmVw7wrk1y/KxUCAAAAa+/AnMt9V5I3VdWTktyT5Nsya368raquSvLHSV6xOyUCAAAA626uBkZ335bk0CZ3vWTccgAAAACeaJ5zYAAAAAAslQYGAAAAMHkaGAAAAMDkaWAAAAAAk6eBAQAAAEyeBgYAAAAweRoYAAAAwORpYAAAAACTp4EBAAAATJ4GBgAAADB5GhgAAADA5GlgAAAAAJOngQEAAABM3oF5Fqqqe5M8lOSRJJ/t7kNV9bQk1yW5IMm9Sb6puz+5O2UCAAAA62w7IzBe1N0Xdfeh4fY1SW7q7guT3DTcBgAAABjdIoeQXJ7k8HD9cJIrFi8HAAAA4InmbWB0kvdU1fur6uph3jndfX+SDJdnb7ZiVV1dVUeq6sixY8cWrxjWkBzBOGQJxiFLsDg5gu2bt4Hxgu6+OMnLk3xHVb1w3gfo7mu7+1B3Hzp48OCOioR1J0cwDlmCccgSLE6OYPvmamB09yeGy6NJ3pnkkiQPVNW5STJcHt2tIgEAAID1tmUDo6qeUlVnHr+e5KVJ7khyQ5Irh8WuTHL9bhUJAAAArLd5vkb1nCTvrKrjy7+5u99VVe9L8raquirJHyd5xe6VCQAAAKyzLRsY3X1PkudsMv9/JXnJbhQFAAAAsNEiX6MKAAAAsCc0MAAAAIDJ08AAAAAAJk8DAwAAAJg8DQwAAABg8jQwAAAAgMnTwAAAAAAmTwMDAAAAmDwNDAAAAGDyNDAAAACAydPAAAAAACZPAwMAAACYvLkbGFV1WlV9sKp+fbj9zKq6tarurqrrqupJu1cmAAAAsM62MwLjNUnu2nD7dUl+srsvTPLJJFeNWRgAAADAcXM1MKrq/CRfneQXhtuV5MVJ3j4scjjJFbtRIAAAAMC8IzB+Ksm/SPIXw+3PT/Kp7v7scPu+JOeNXBsAAABAkjkaGFX1NUmOdvf7N87eZNE+yfpXV9WRqjpy7NixHZYJ602OYByyBOOQJVicHMH2zTMC4wVJvraq7k3y1swOHfmpJGdV1YFhmfOTfGKzlbv72u4+1N2HDh48OELJsH7kCMYhSzAOWYLFyRFs35YNjO7+vu4+v7svSPKqJP+1u78lyc1JvnFY7Mok1+9alQAAAMBa2863kJzoe5P806r6aGbnxHjDOCUBAAAAPN6BrRd5THffkuSW4fo9SS4ZvyQAAACAx1tkBAYAAADAntDAAAAAACZPAwMAAACYvG2dAwMAYJVUbT2/e29qAQAWYwQGAAAAMHkaGAAAAMDkaWAAAAAAk6eBAQAAAEyeBgYAAAAweRoYAAAAwORpYAAAAACTp4EBAAAATJ4GBgAAADB5WzYwqupzq+p3q+pDVXVnVf3gMP+ZVXVrVd1dVddV1ZN2v1wAAABgHc0zAuPTSV7c3c9JclGSS6vqeUlel+Qnu/vCJJ9MctXulQkAAACssy0bGD3z8HDz9GHqJC9O8vZh/uEkV+xKhQAAAMDam+scGFV1WlXdluRokhuT/GGST3X3Z4dF7kty3knWvbqqjlTVkWPHjo1RM6wdOYJxyBKMQ5ZgcXIE2zdXA6O7H+nui5Kcn+SSJF+y2WInWffa7j7U3YcOHjy480phjckRjEOWYByyBIuTI9i+bX0LSXd/KsktSZ6X5KyqOjDcdX6ST4xbGgAAAMDMPN9CcrCqzhquPznJ301yV5Kbk3zjsNiVSa7frSIBAACA9XZg60VybpLDVXVaZg2Pt3X3r1fV7yV5a1X9UJIPJnnDLtYJAAAArLEtGxjd/eEkz91k/j2ZnQ8DAAAAYFdt6xwYAAAAAMswzyEkAAAro2rZFQAAu8EIDAAAAGDyNDAAAACAydPAAAAAACZPAwMAAACYPA0MAAAAYPJ8CwkAsKs2fitI9/LqAABWmxEYAAAAwORpYAAAAACTp4EBAAAATJ5zYAAAK2/jeTYAgP1pyxEYVfWMqrq5qu6qqjur6jXD/KdV1Y1Vdfdw+dTdLxcAAABYR/McQvLZJP+su78kyfOSfEdVPTvJNUlu6u4Lk9w03AYAAAAY3ZYNjO6+v7s/MFx/KMldSc5LcnmSw8Nih5NcsVtFAgAAAOttWyfxrKoLkjw3ya1Jzunu+5NZkyPJ2WMXBwAAAJBso4FRVWck+dUk393df7aN9a6uqiNVdeTYsWM7qRHWnhzBOGRpf6h6bGI5ZGm9yeA45Ai2b64GRlWdnlnz4k3d/Y5h9gNVde5w/7lJjm62bndf292HuvvQwYMHx6gZ1o4cwThkCcYhS7A4OYLtm+dbSCrJG5Lc1d0/seGuG5JcOVy/Msn145cHAAAAkByYY5kXJPnWJLdX1W3DvH+Z5EeSvK2qrkryx0lesTslAgAAAOtuywZGd/+3JCc7wu0l45YDAOxnmx0z3733dQAAq2db30ICAAAAsAzzHEICALAnNo7Q2Dgyw7cdwHLJIDAFRmAAAAAAk2cEBgCwsnwqDADrwwgMAAAAYPKMwACANTXP+Sa2+oaQ7Sw7Vcefw6rWDwDrwggMAAAAYPI0MAAAAIDJcwgJADC6MU6uucwTdO6HQ2MAYL8xAgMAAACYPCMwAGANjDGiwFeWAgDLZAQGAAAAMHlGYAAAS2VkBwAwjy1HYFTVG6vqaFXdsWHe06rqxqq6e7h86u6WCQAAAKyzeQ4h+aUkl54w75okN3X3hUluGm4DAHuk6rEJYF4bf3acOAFM3ZYNjO7+zSR/csLsy5McHq4fTnLFyHUBAAAAPGqnJ/E8p7vvT5Lh8uyTLVhVV1fVkao6cuzYsR0+HKw3OVpfPhUb137I0mbvie1+gup9tTmfRM9vP2SJUzM6Y/fJEWzfrn8LSXdf292HuvvQwYMHd/vhYF+SIxiHLME4ZAkWJ0ewfTttYDxQVecmyXB5dLySAPYvn2YxVWO8N/fr+3u/Pi+Ww/sJYOd22sC4IcmVw/Urk1w/TjkAAAAATzTP16i+Jcl7k3xxVd1XVVcl+ZEkX1VVdyf5quE2AAAAwK44sNUC3f3NJ7nrJSPXAsBJbDbUuHvv6wAAgGXZ9ZN4AgAAACxqyxEYAOwNJ3RjDN5HsHtOzNd+Gwm36M+P/f76AMtnBAYAAAAweUZgAOyC459CzfPpk0/M18/GfX6y98g8y+wF70/YGzvJ/KlGPOzVzxA/I4C9ZAQGAAAAMHlGYADsQ9sZAcJyTWWkBQDA1BmBAQAAAEyeERjAUvn0GR7jWHJYL/s9837Hsx/t9H19qvVkZX5GYAAAAACTZwQGsKd289wMO/3mj+0sv9O69/unbMxnp+8D7x/YuUW/3eNU65xsuUU/TZ3320V2ur1l8AkzJzrV31b74Vxe+/35LYsRGAAAAMDkGYExMYt04/aykzfPY53q04N51tGRZCefgG01f7vvw3nsNHuLfiK20+cHjMPvrN0x9uiFRR9nJ9vbyfo72fZuPNZekJ29NfXXe7v/VxxfbrP1djoa98Rtz7v8ovexfUZgAAAAAJO3UAOjqi6tqo9U1Uer6pqxigIAAADYaMeHkFTVaUl+NslXJbkvyfuq6obu/r2xilvUToYQzTNs6FQnYjnuxKFNm603lZO3nFjHdp7nVJ4D49rJ4T/b2d6iyy2ync3uW3S44Tz37ZUp1LCf7NVhSKyOrQ4T8Ptwd81z0sx5159nPrtv7L85FjW1eqZiO/8fbDTP/xe76VSHnsy73hjLbcfJ/jfbaJ3fl4uMwLgkyUe7+57u/kyStya5fJyyAAAAAB6zyEk8z0vysQ2370vyN09cqKquTnL1cPPhqvrIAo+5I9vpjFXl6UkeXHR7p/qUd5Fl5/D0qlPXfzInG12xk3V3uszg6UkeXOFPQ071HnpXd1+63Q0uO0c73BenzNJOT5S5m054jC1/Fuxgm3tJjjYxRpaW8JqO8l5corWqf4KZm2yW5nucnd23ibV6H07Q3PVPLUMb6jnZc5h8jh7/mAuvv9DPxJ2Okt3uNk8xb9S/Txe1g59xa//3XfUOx59U1SuSvKy7v324/a1JLunu79rRBieiqo5096Fl17FTq15/svrPYdXrH8uqvw7qX65Vr39Mq/5aqH+5Vr3+saz666D+5dsPz2EMq/46qH+5xqh/kUNI7kvyjA23z0/yiUWKAQAAANjMIg2M9yW5sKqeWVVPSvKqJDeMUxYAAADAY3Z8Dozu/mxVfWeSdyc5Lckbu/vO0SpbnmuXXcCCVr3+ZPWfw6rXP5ZVfx3Uv1yrXv+YVv21UP9yrXr9Y1n110H9y7cfnsMYVv11UP9yLVz/js+BAQAAALBXFjmEBAAAAGBPaGAAAAAAk7f2DYyqureqbq+q26rqyDDvaVV1Y1XdPVw+ddl1HldVb6yqo1V1x4Z5m9ZbMz9TVR+tqg9X1cXLq/zRWjer/7VV9fFhH9xWVZdtuO/7hvo/UlUvW07Vj6mqZ1TVzVV1V1XdWVWvGeavzD7YDauWo0SWllP1Y2Rpc6uWpVXPUbLaWZKjk5OlvbXKORrqkaVNrFqOEllaTtWP2ZMsdfdaT0nuTfL0E+b9aJJrhuvXJHndsuvcUNsLk1yc5I6t6k1yWZL/nKSSPC/JrROt/7VJvmeTZZ+d5ENJPifJM5P8YZLTllz/uUkuHq6fmeQPhjpXZh/s0uuyUjkaapKl5dYvS5u/LiuVpVXP0Smew0pkSY5O+drI0vLrX4kcDTXJ0uavy0rlaKhJlpZb/65nae1HYJzE5UkOD9cPJ7liibU8Tnf/ZpI/OWH2yeq9PMkv98zvJDmrqs7dm0o3d5L6T+byJG/t7k939x8l+WiSS3atuDl09/3d/YHh+kNJ7kpyXlZoH+yhyeYokaXI0iqZbJZWPUfJamdJjrZNlnbJKucokaVtmmyOElnKGmRJAyPpJO+pqvdX1dXDvHO6+/5kthOSnL206uZzsnrPS/KxDcvdN8ybou8chg29ccNQtEnXX1UXJHlukluzP/bBIvZDjpL9sR9labXthyztl324UlmSoyeQpWlYqRwlsnSC/ZCjZH/sR1kaaGAkL+jui5O8PMl3VNULl13QiGqTeVP83tyfS/LXklyU5P4kPz7Mn2z9VXVGkl9N8t3d/WenWnSTeZN4DiPbzzlKVmc/ytLq289ZWqV9uFJZkqNNydLyrVSOElnaxH7OUbI6+1GWNlj7BkZ3f2K4PJrknZkNu3ng+NCV4fLo8iqcy8nqvS/JMzYsd36ST+xxbVvq7ge6+5Hu/oskr89jQ58mWX9VnZ5ZIN/U3e8YZq/0PljUPslRsuL7UZZW3z7J0srvw1XKkhxtTpaWb5VylMjSZvZJjpIV34+y9Hhr3cCoqqdU1ZnHryd5aZI7ktyQ5MphsSuTXL+cCud2snpvSPL3h7O7Pi/Jnx4fujMlJxzn9HWZ7YNkVv+rqupzquqZSS5M8rt7Xd9GVVVJ3pDkru7+iQ13rfQ+WMQ+ylGy4vtRllbbPsrSyu/DVcmSHG1OlqZhVXKUyNJm9lGOkhXfj7J0gp7A2WKXNSX5wszO3PqhJHcm+f5h/ucnuSnJ3cPl05Zd64aa35LZ0KH/l1nH6qqT1ZvZkJyfzeyMtLcnOTTR+v/TUN+HhzfxuRuW//6h/o8kefkE6v/bmQ1r+nCS24bpslXaB7vwmqxcjk7xXlyZ/ShLy98Hu/CarFyWVj1Hp3gOK5ElOTrp6yJL06h/JXI01CNLT3xNVi5Hp3gvrsx+lKWt90ENKwIAAABM1lofQgIAAACsBg0MAAAAYPI0MAAAAIDJ08AAAAAAJk8DAwAAAJg8DYwVU1UP78I2L6qqyzbcfm1Vfc/YjwNTIkuwODmCccgSjEOW9j8NDJLkosy+nxdYjCzB4uQIxiFLMA5ZmhANjBVWVf+8qt5XVR+uqh8c5l1QVXdV1eur6s6qek9VPXm4728My763qv59Vd1RVU9K8m+SvLKqbquqVw6bf3ZV3VJV91TVP17SU4Q9IUuwODmCccgSjEOW9icNjBVVVS9NcmGSSzLrCn5FVb1wuPvCJD/b3V+a5FNJvmGY/4tJ/mF3Pz/JI0nS3Z9J8gNJruvui7r7umHZZyV52bD9f11Vp+/B04I9J0uwODmCccgSjEOW9i8NjNX10mH6YJIPZBaiC4f7/qi7bxuuvz/JBVV1VpIzu/u3h/lv3mL7v9Hdn+7uB5McTXLOqNXDdMgSLE6OYByyBOOQpX3qwLILYMcqyQ9393983MyqC5J8esOsR5I8eVh+O07chvcK+5UsweLkCMYhSzAOWdqnjMBYXe9O8g+q6owkqarzqursky3c3Z9M8lBVPW+Y9aoNdz+U5MxdqxSmTZZgcXIE45AlGIcs7VMaGCuqu9+T2dCm91bV7Unenq2DdVWSa6vqvZl1Gf90mH9zZiei2XhiGlgLsgSLkyMYhyzBOGRp/6ruXnYN7JGqOqO7Hx6uX5Pk3O5+zZLLgpUjS7A4OYJxyBKMQ5ZWg2N11stXV9X3Zbbf/0eSVy+3HFhZsgSLkyMYhyzBOGRpBRiBAQAAAEyec2AAAAAAk6eBAQAAAEyeBgYAAAAweRoYAAAAwORpYAAAAACT9/8BoJS9R0Dn3L4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# COMPARING TEXT LENGTH TO Sentiments\n",
    "graph = sns.FacetGrid(data=data,col='sentiment')\n",
    "graph.map(plt.hist,'length',bins=50,color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying the dataset and splitting it into the reviews and given sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFICATION\n",
    "#data_classes = data[(data['sentiment']==1) | (data['sentiment']==3) | (data['sentiment']==5)]\n",
    "#data_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_classes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We have got a smaller dataset. Better way is to do sentiment analysis. See what are positive , negative and neutral emotions and then rank them accordingly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vectorize and lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "class LemmaCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(LemmaCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: (lemm.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=data['cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    manjulamartin kirk gleason except train capita...\n",
       "1                           want google driverless car\n",
       "2    oatmeal google driverless teslamotors ooooh wo...\n",
       "3    much awesome amazing video google next phase d...\n",
       "4    google making driverless car awesome http co h...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_vectorizer = LemmaCountVectorizer(max_df=0.95, \n",
    "                                     #min_df=2,\n",
    "                                     #stop_words='english',\n",
    "                                     #decode_error='ignore')\n",
    "#tf = tf_vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfeature_names = tf_vectorizer.get_feature_names()\\ncount_vec = np.asarray(tf.sum(axis=0)).ravel()\\nzipped = list(zip(feature_names, count_vec))\\nx, y = (list(x) for x in zip(*sorted(zipped, key=lambda x: x[1], reverse=True)))\\n# Now I want to extract out on the top 15 and bottom 15 words\\nY = np.concatenate([y[0:15], y[-16:-1]])\\nX = np.concatenate([x[0:15], x[-16:-1]])\\n\\n# Plotting the Plot.ly plot for the Top 50 word frequencies\\ndata = [go.Bar(\\n            x = x[0:50],\\n            y = y[0:50],\\n            marker= dict(colorscale='Jet',\\n                         color = y[0:50]\\n                        ),\\n            text='Word counts'\\n    )]\\n\\nlayout = go.Layout(\\n    title='Top 50 Word frequencies after Preprocessing'\\n)\\n\\nfig = go.Figure(data=data, layout=layout)\\n\\npy.iplot(fig, filename='basic-bar')\\n\\n# Plotting the Plot.ly plot for the Top 50 word frequencies\\ndata = [go.Bar(\\n            x = x[-100:],\\n            y = y[-100:],\\n            marker= dict(colorscale='Portland',\\n                         color = y[-100:]\\n                        ),\\n            text='Word counts'\\n    )]\\n\\nlayout = go.Layout(\\n    title='Bottom 100 Word frequencies after Preprocessing'\\n)\\n\\nfig = go.Figure(data=data, layout=layout)\\n\\npy.iplot(fig, filename='basic-bar')\\n\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "feature_names = tf_vectorizer.get_feature_names()\n",
    "count_vec = np.asarray(tf.sum(axis=0)).ravel()\n",
    "zipped = list(zip(feature_names, count_vec))\n",
    "x, y = (list(x) for x in zip(*sorted(zipped, key=lambda x: x[1], reverse=True)))\n",
    "# Now I want to extract out on the top 15 and bottom 15 words\n",
    "Y = np.concatenate([y[0:15], y[-16:-1]])\n",
    "X = np.concatenate([x[0:15], x[-16:-1]])\n",
    "\n",
    "# Plotting the Plot.ly plot for the Top 50 word frequencies\n",
    "data = [go.Bar(\n",
    "            x = x[0:50],\n",
    "            y = y[0:50],\n",
    "            marker= dict(colorscale='Jet',\n",
    "                         color = y[0:50]\n",
    "                        ),\n",
    "            text='Word counts'\n",
    "    )]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Top 50 Word frequencies after Preprocessing'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='basic-bar')\n",
    "\n",
    "# Plotting the Plot.ly plot for the Top 50 word frequencies\n",
    "data = [go.Bar(\n",
    "            x = x[-100:],\n",
    "            y = y[-100:],\n",
    "            marker= dict(colorscale='Portland',\n",
    "                         color = y[-100:]\n",
    "                        ),\n",
    "            text='Word counts'\n",
    "    )]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Bottom 100 Word frequencies after Preprocessing'\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "py.iplot(fig, filename='basic-bar')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Shape of the matrix:\\nprint(\"Shape of the sparse matrix: \", tf.shape)\\n#Non-zero occurences:\\nprint(\"Non-Zero occurences: \",tf.nnz)\\n\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Shape of the matrix:\n",
    "print(\"Shape of the sparse matrix: \", tf.shape)\n",
    "#Non-zero occurences:\n",
    "print(\"Non-Zero occurences: \",tf.nnz)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# DENSITY OF THE MATRIX\\ndensity = (tf.nnz/(tf.shape[0]*tf.shape[1]))*100\\nprint(\"Density of the matrix = \",density)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# DENSITY OF THE MATRIX\n",
    "density = (tf.nnz/(tf.shape[0]*tf.shape[1]))*100\n",
    "print(\"Density of the matrix = \",density)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating key features for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>@manjulamartin @Kirk_Gleason Except trains are...</td>\n",
       "      <td>manjulamartin kirk gleason except train capita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I want a Google driverless car.</td>\n",
       "      <td>want google driverless car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>@Oatmeal @google driverless @TeslaMotors ? Ooo...</td>\n",
       "      <td>oatmeal google driverless teslamotors ooooh wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>SO MUCH AWESOME! Amazing video for GoogleÌ¢‰âÂ...</td>\n",
       "      <td>much awesome amazing video google next phase d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@google is making driverless cars which is awe...</td>\n",
       "      <td>google making driverless car awesome http co h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          5  @manjulamartin @Kirk_Gleason Except trains are...   \n",
       "1          5                    I want a Google driverless car.   \n",
       "2          5  @Oatmeal @google driverless @TeslaMotors ? Ooo...   \n",
       "3          5  SO MUCH AWESOME! Amazing video for GoogleÌ¢‰âÂ...   \n",
       "4          5  @google is making driverless cars which is awe...   \n",
       "\n",
       "                                             cleaned  \n",
       "0  manjulamartin kirk gleason except train capita...  \n",
       "1                         want google driverless car  \n",
       "2  oatmeal google driverless teslamotors ooooh wo...  \n",
       "3  much awesome amazing video google next phase d...  \n",
       "4  google making driverless car awesome http co h...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_self_drive_clean.csv', index_col= None)\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Two places I'd invest all my money if I could:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Awesome! Google driverless cars will help the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Autonomous vehicles could reduce traffic fatal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Really good presentation from Jan Becker on Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ford just revealed it's Automated Ford Fusion ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text\n",
       "0   1  Two places I'd invest all my money if I could:...\n",
       "1   2  Awesome! Google driverless cars will help the ...\n",
       "2   3  Autonomous vehicles could reduce traffic fatal...\n",
       "3   4  Really good presentation from Jan Becker on Bo...\n",
       "4   5  Ford just revealed it's Automated Ford Fusion ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('test.csv')\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### working with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=data['cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=data_test['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the vectorizer\n",
    "vect = CountVectorizer()\n",
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "vect.fit(train)\n",
    "train_dtm = vect.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<981x3758 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11403 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "2    5\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=data['sentiment']\n",
    "target[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=data_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<979x3758 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7297 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for our test set\n",
    "test_dtm = vect.transform(test)\n",
    "test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "- `vect.fit(train)` **learns the vocabulary** of the training data\n",
    "- `vect.transform(train)` uses the **fitted vocabulary** to build a document-term matrix from the training data\n",
    "- `vect.transform(test)` uses the **fitted vocabulary** to build a document-term matrix from the testing data (and **ignores tokens** it hasn't seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(train_dtm,target)\n",
    "predmnb = mnb.predict(test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.71"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_log = round(mnb.score(train_dtm, target) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
